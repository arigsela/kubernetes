# Grafana Observability Stack: Loki (Logs) + Prometheus (Metrics) + Alloy - Implementation Plan

**Document Version:** 3.0
**Created:** 2025-10-16
**Last Updated:** 2025-10-17
**Status:** Ready for Implementation (GitOps with Crossplane)
**Cluster:** K3s Homelab
**Stack:** Complete Observability (Logs + Metrics)

### Component Versions (Latest as of 2025-10-17)
- **Grafana Loki:** v3.5.7 (released 2025-10-16)
- **Prometheus:** v3.7.0 (released 2025-10-15)
- **Grafana Alloy:** v1.11.0 (includes Prometheus v3.4.2 dependency)
- **Crossplane AWS Provider:** v2.1.1 (provider-family-aws)

**Important Notes:**
- Prometheus: Do not use `:latest` tag as it still points to v2.53.5. Use explicit `v3.7.0`
- Alloy v1.11.0: Includes breaking changes from Prometheus v3.4.2 upgrade where `.` pattern in PromQL now matches newlines
- **GitOps:** All AWS resources (S3, IAM) managed via Crossplane - no manual AWS CLI commands needed!

---

## Table of Contents
1. [Executive Summary](#executive-summary)
2. [Architecture Overview](#architecture-overview)
3. [Cost Analysis](#cost-analysis)
4. [Prerequisites](#prerequisites)
5. [Implementation Phases](#implementation-phases)
6. [Configuration Details](#configuration-details)
7. [Testing & Validation](#testing--validation)
8. [Operations & Maintenance](#operations--maintenance)
9. [Troubleshooting](#troubleshooting)
10. [Rollback Plan](#rollback-plan)

---

## Executive Summary

### Objective
Deploy a **complete observability stack** with Grafana Loki (logs), Prometheus (metrics), and Grafana Alloy (unified collector) for your K3s homelab cluster. This provides logs AND metrics with label correlation, enabling you to jump between metrics and logs seamlessly.

### Key Benefits
- **Complete Observability:** Logs (Loki) + Metrics (Prometheus) + Unified Collection (Alloy)
- **Cost Efficiency:** ~$1-3/month total vs $1,200-4,500/month for Datadog equivalent
- **Modern Stack:** Grafana Alloy (2025) collects both logs and metrics in a single agent
- **100% GitOps:** ALL resources (K8s + AWS) managed via ArgoCD with Crossplane - zero manual CLI commands
- **Infrastructure as Code:** S3 buckets, IAM users/policies deployed declaratively through Git
- **Scalability:** S3 for logs (unlimited), local storage for metrics (15-day retention)
- **Label Correlation:** Jump from high CPU metric → related error logs instantly
- **Compression:** 5-10x log compression reduces storage costs significantly
- **Disaster Recovery:** Recreate entire infrastructure from Git repository

### The Power of Logs + Metrics Together

```
Scenario: Your app is slow

1. Check Prometheus: CPU at 95%! ⚠️
2. Click to jump to logs in Loki
3. See logs: "Database connection pool exhausted"
4. Root cause found in 30 seconds! ✅
```

Without metrics, you'd only see logs saying "slow" but not know WHY.
Without logs, you'd see high CPU but not know WHAT caused it.

**Together = Complete Observability!**

### Success Criteria
- ✅ All pod **logs** collected and viewable in Grafana (via Loki)
- ✅ All pod **metrics** collected and queryable in Grafana (via Prometheus)
- ✅ Label correlation works (same labels on logs and metrics)
- ✅ 30-day log retention with automated S3 lifecycle management
- ✅ 15-day metric retention with automatic cleanup
- ✅ Query response time <2 seconds for recent data
- ✅ Monthly AWS S3 cost <$5
- ✅ Zero data loss during deployment
- ✅ ArgoCD auto-sync enabled for all components

---

## Architecture Overview

### High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────────┐
│                         K3s Cluster                                  │
│                                                                      │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐             │
│  │ Chores       │  │ Frontend     │  │ Cert Manager │  ...        │
│  │ Tracker      │  │ Apps         │  │ etc          │             │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘             │
│         │                  │                  │                      │
│         │ Exposes /metrics endpoint (Prometheus format)            │
│         │                  │                  │                      │
│         └──────────────────┴──────────────────┘                     │
│                           │                                          │
│         ┌─────────────────▼──────────────────┐                     │
│         │   Grafana Alloy (DaemonSet)        │                     │
│         │                                     │                     │
│         │   LOG PATH:                         │                     │
│         │   ├─ Scrapes /var/log/containers/  │                     │
│         │   ├─ Extracts labels                │                     │
│         │   ├─ Filters & parses               │                     │
│         │   └─ Pushes to Loki                 │                     │
│         │                                     │                     │
│         │   METRICS PATH:                     │                     │
│         │   ├─ Discovers service endpoints    │                     │
│         │   ├─ Scrapes /metrics               │                     │
│         │   ├─ Adds same labels as logs       │                     │
│         │   └─ Writes to Prometheus           │                     │
│         └─────┬───────────────────┬───────────┘                     │
│               │                   │                                  │
│         LOGS  │                   │  METRICS                         │
│               │                   │                                  │
│    ┌──────────▼─────────┐  ┌─────▼──────────────┐                 │
│    │   Loki             │  │   Prometheus        │                 │
│    │   - Chunks logs    │  │   - Stores metrics  │                 │
│    │   - Compresses     │  │   - Local storage   │                 │
│    │   - Indexes labels │  │   - 15-day retention│                 │
│    └──────────┬─────────┘  └─────┬──────────────┘                 │
│               │                   │                                  │
└───────────────┼───────────────────┼──────────────────────────────────┘
                │                   │
                │ S3 API            │ Query API (PromQL)
                ▼                   │
      ┌─────────────────┐          │
      │    AWS S3       │          │
      │   (Log Chunks)  │          │
      └─────────────────┘          │
                │                   │
                │ Query (LogQL)     │
                │                   │
         ┌──────▼───────────────────▼─────┐
         │         Grafana                 │
         │                                 │
         │  Data Sources:                  │
         │  ├─ Loki (logs)                 │
         │  └─ Prometheus (metrics)        │
         │                                 │
         │  Features:                      │
         │  ├─ Unified dashboards          │
         │  ├─ Label correlation           │
         │  ├─ Jump from metric→log        │
         │  └─ Alerts on both              │
         └─────────────────────────────────┘
```

### Components

| Component | Purpose | Deployment Type | Resources | Storage |
|-----------|---------|-----------------|-----------|---------|
| **Crossplane AWS Provider** | **Manages AWS infrastructure (S3, IAM)** | **Provider** | **50MB RAM** | **-** |
| Grafana Alloy | **Logs AND metrics** collection | DaemonSet | 150MB RAM, 0.2 CPU per node | - |
| Loki (All-in-one mode) | Log aggregation & storage | Deployment | 1GB RAM, 0.5 CPU | AWS S3 (Crossplane-managed) |
| **Prometheus** | **Metrics storage & querying** | **StatefulSet** | **1GB RAM, 0.5 CPU** | **Local 50GB** |
| Grafana | Visualization & querying | Deployment | 512MB RAM, 0.2 CPU | - |
| AWS S3 | Long-term log storage | Crossplane-managed | - | ~$0.50-3/month |
| AWS IAM | Loki S3 access credentials | Crossplane-managed | - | - |

**Total Resource Requirements:** ~2.7GB RAM, ~1.4 CPU

### Data Flow

#### Log Flow (Loki)
1. **Collection:** Alloy scrapes logs from `/var/log/containers/*.log`
2. **Labeling:** Alloy extracts Kubernetes metadata (namespace, pod, container)
3. **Filtering:** Optional log filtering to reduce noise
4. **Shipping:** Alloy pushes logs to Loki Distributor via HTTP
5. **Processing:** Loki chunks, compresses, and indexes metadata
6. **Storage:** Compressed chunks written to S3
7. **Querying:** Grafana queries Loki using LogQL
8. **Retrieval:** Loki fetches chunks from S3 and in-memory cache

#### Metrics Flow (Prometheus)
1. **Discovery:** Alloy discovers pods with `prometheus.io/scrape: "true"` annotation
2. **Scraping:** Alloy scrapes `/metrics` endpoints every 15 seconds
3. **Labeling:** Alloy adds same labels as logs (namespace, pod, container, app)
4. **Shipping:** Alloy writes metrics to Prometheus via remote_write API
5. **Storage:** Prometheus stores metrics in local TSDB (15-day retention)
6. **Querying:** Grafana queries Prometheus using PromQL
7. **Correlation:** Same labels enable jumping between logs and metrics

---

## Cost Analysis

### AWS S3 Monthly Cost Estimate

**Assumptions:**
- Current infrastructure: ~15-20 active pods
- Log generation: 3-5 GB/day raw logs
- Compression ratio: 10x (Loki Snappy)
- Retention: 30 days

#### Breakdown

| Item | Calculation | Monthly Cost |
|------|-------------|--------------|
| **Log Generation** | 5 GB/day × 30 days = 150 GB raw | - |
| **After Compression** | 150 GB ÷ 10 = 15 GB stored | - |
| **S3 Standard Storage** | 15 GB × $0.023/GB | **$0.35** |
| **PUT Requests** | ~150 requests/day × 30 × $0.005/1000 | **$0.02** |
| **GET Requests** | ~100 queries/day × 30 × $0.0004/1000 | **$0.001** |
| **Data Transfer OUT** | Minimal (queries return small results) | **$0.05** |
| **TOTAL (Logs)** | | **~$0.50-1.00/month** |

### Complete Stack Monthly Costs

| Component | Storage/Cost | Notes |
|-----------|--------------|-------|
| **Loki (S3)** | **$0.50-3/month** | 30-day log retention |
| **Prometheus (Local)** | **$0/month** | 15-day metric retention, uses local storage |
| **Total** | **$0.50-3/month** | Same as logs-only! |

**Why Prometheus is Free:**
- Uses local Kubernetes persistent volume (K3s local-path)
- No cloud storage costs
- 15-day retention is sufficient for metrics
- Older metrics rarely needed (unlike logs)

#### Scaling Estimates

| Scenario | Pods | Raw Logs/Day | Stored (30d) | Monthly Cost |
|----------|------|--------------|--------------|--------------|
| Small | 5-10 | 1-2 GB | 3-6 GB | **$0.15-0.30** |
| Current | 15-20 | 3-5 GB | 15 GB | **$0.50-1.00** |
| Large | 50+ | 10-20 GB | 60 GB | **$2-3** |

#### 90-Day Retention

| Scenario | Stored (90d) | Monthly Cost |
|----------|--------------|--------------|
| Small | 9-18 GB | **$0.45-0.90** |
| Current | 45 GB | **$1.50-3.00** |
| Large | 180 GB | **$6-9** |

### Cost Optimization Strategies

1. **S3 Lifecycle Policies** (Recommended)
   ```yaml
   - After 30 days: Move to S3 Standard-IA ($0.0125/GB) → 46% savings
   - After 90 days: Move to Glacier Deep Archive ($0.00099/GB) → 96% savings
   ```

2. **Loki Retention Configuration**
   - Automatically delete logs after N days
   - No manual cleanup required

3. **Log Filtering at Alloy**
   - Filter debug logs, health checks, verbose logs
   - Reduce log volume by 30-50%

4. **Compression Tuning**
   - Default: Snappy (fast, good compression)
   - Alternative: gzip (slower, better compression)

### ROI Comparison

| Solution | Setup Time | Monthly Cost | Annual Cost |
|----------|------------|--------------|-------------|
| **Loki + Prometheus** | 5-6 hours | $0.50-3 | **$6-36** |
| Grafana Cloud (Free) | 1 hour | $0 | $0 (50GB limit) |
| Datadog | 2 hours | $1,200-4,500 | $14,400-54,000 |
| ELK on EBS | 8-12 hours | $10-30 | $120-360 |

**Savings vs Datadog:** 99.9% ($14,394-53,964/year)

---

## Prerequisites

### Required Tools & Access

- [x] kubectl access to K3s cluster
- [x] ArgoCD admin access
- [x] AWS account with IAM admin permissions (for Crossplane)
- [x] Vault access for secrets management
- [x] Git repository access (this repo)
- [x] Crossplane installed in cluster (core components)
- [x] External Secrets Operator installed

### AWS Root Credentials Setup (One-Time)

**Note:** This is the ONLY manual step. After this, all AWS resources are managed by Crossplane via GitOps.

#### Option 1: Terraform (Recommended - Infrastructure as Code) ✅

**You already have Terraform set up!** Use it to create the Crossplane admin user and credentials:

```bash
# Navigate to Terraform directory
cd terraform/roots/asela-cluster

# Review the new iam.tf file
cat iam.tf

# Initialize if needed
terraform init

# Review what will be created
terraform plan

# Apply changes
terraform apply

# This creates:
# 1. IAM user: crossplane-admin
# 2. IAM policy with S3 + IAM permissions
# 3. Access keys
# 4. Kubernetes secret: aws-secret in crossplane-system namespace
```

**✅ Done!** The secret is automatically created in your cluster by Terraform. No manual kubectl commands needed!

**To verify:**
```bash
# Check the secret was created
kubectl get secret aws-secret -n crossplane-system

# View the outputs
terraform output crossplane_admin_access_key_id
terraform output crossplane_admin_user_arn
```

#### Option 2: Manual AWS CLI (If not using Terraform)

```bash
# 1. Create IAM user for Crossplane with admin permissions
aws iam create-user --user-name crossplane-admin

# 2. Create and attach inline policy with S3 + IAM permissions
aws iam put-user-policy \
  --user-name crossplane-admin \
  --policy-name crossplane-admin-policy \
  --policy-document '{
    "Version": "2012-10-17",
    "Statement": [
      {"Effect": "Allow", "Action": "s3:*", "Resource": "*"},
      {"Effect": "Allow", "Action": "iam:*", "Resource": "*"}
    ]
  }'

# 3. Create access keys
aws iam create-access-key --user-name crossplane-admin

# 4. Save output - you'll need AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
export AWS_ACCESS_KEY_ID="AKIAXXXXXXXXXXXXXXXX"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"

# 5. Create Kubernetes secret
kubectl create secret generic aws-secret \
  -n crossplane-system \
  --from-literal=creds="[default]
aws_access_key_id = ${AWS_ACCESS_KEY_ID}
aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}
"
```

#### Option 3: IRSA (IAM Roles for Service Accounts) - For Production

See Crossplane documentation for IRSA setup: https://docs.crossplane.io/latest/concepts/providers/

**Important:** This secret contains root AWS credentials with S3 and IAM permissions. Protect your Terraform state file! After Crossplane creates the Loki IAM user, that user will have limited S3-only permissions.

### Vault Configuration (Unchanged)

Create Vault role for logging namespace:

```bash
# Create Vault policy
vault policy write logging-s3 - <<EOF
path "k8s-secrets/data/logging/*" {
  capabilities = ["read"]
}
EOF

# Create Kubernetes auth role
vault write auth/kubernetes/role/logging \
  bound_service_account_names=default,loki,alloy,prometheus \
  bound_service_account_namespaces=logging \
  policies=logging-s3 \
  ttl=24h
```

**Note:** The Loki S3 credentials will be automatically created by Crossplane and synced to Vault via ExternalSecret. No manual credential storage needed!

---

## Implementation Phases

### Overview

| Phase | Description | Duration | Completion |
|-------|-------------|----------|------------|
| **Phase 1** | **Crossplane AWS Provider Setup (GitOps)** | **1.5 hours** | ⬜ **0/5 tasks** |
| **Phase 1.5** | **AWS Infrastructure via Crossplane (GitOps)** | **1 hour** | ⬜ **0/7 tasks** |
| Phase 2 | Loki Deployment | 1 hour | ⬜ 0/5 tasks |
| **Phase 2.5** | **Prometheus Deployment** | **45 min** | ⬜ **0/3 tasks** |
| Phase 3 | Grafana Alloy Deployment (Enhanced) | 1 hour | ⬜ 0/4 tasks |
| Phase 4 | Grafana Integration (Complete) | 30 min | ⬜ 0/4 tasks |
| Phase 5 | Testing & Validation | 1 hour | ⬜ 0/6 tasks |
| Phase 6 | Production Optimization | 30 min | ⬜ 0/4 tasks |

**Total Estimated Time:** 7.25 hours (one-time investment for full GitOps automation)
**Overall Progress:** 0% (0/38 tasks completed)

---

### Phase 1: Crossplane AWS Provider Setup (1.5 hours)

**Objective:** Install and configure Crossplane AWS provider to manage all AWS resources via GitOps

#### Tasks

- [ ] **Task 1.1:** Install Crossplane AWS Provider

  Create file: `base-apps/crossplane-aws-provider/provider.yaml`
  ```yaml
  apiVersion: pkg.crossplane.io/v1
  kind: Provider
  metadata:
    name: provider-aws-s3
  spec:
    package: xpkg.upbound.io/upbound/provider-aws-s3:v1.12.0
  ---
  apiVersion: pkg.crossplane.io/v1
  kind: Provider
  metadata:
    name: provider-aws-iam
  spec:
    package: xpkg.upbound.io/upbound/provider-aws-iam:v1.12.0
  ```

  **Note:** We're installing two providers from the provider-family-aws:
  - `provider-aws-s3`: For S3 bucket and lifecycle management
  - `provider-aws-iam`: For IAM users, policies, and access keys

- [ ] **Task 1.2:** Create ProviderConfig with AWS credentials

  Create file: `base-apps/crossplane-aws-provider/provider-config.yaml`
  ```yaml
  apiVersion: aws.upbound.io/v1beta1
  kind: ProviderConfig
  metadata:
    name: default
  spec:
    credentials:
      source: Secret
      secretRef:
        namespace: crossplane-system
        name: aws-secret
        key: creds
  ```

  **This tells Crossplane how to authenticate with AWS using the secret created in Prerequisites.**

- [ ] **Task 1.3:** Create ArgoCD Application for Crossplane Provider

  Create file: `base-apps/crossplane-aws-provider.yaml`
  ```yaml
  apiVersion: argoproj.io/v1alpha1
  kind: Application
  metadata:
    name: crossplane-aws-provider
    namespace: argo-cd
  spec:
    project: default
    source:
      repoURL: https://github.com/arigsela/kubernetes
      targetRevision: main
      path: base-apps/crossplane-aws-provider
    destination:
      server: https://kubernetes.default.svc
      namespace: crossplane-system
    syncPolicy:
      automated:
        prune: true
        selfHeal: true
      syncOptions:
        - CreateNamespace=false  # crossplane-system already exists
  ```

- [ ] **Task 1.4:** Deploy Crossplane providers

  ```bash
  # Commit and push
  git add base-apps/crossplane-aws-provider*
  git commit -m "Add Crossplane AWS provider for GitOps infrastructure management"
  git push origin main

  # Wait for ArgoCD to sync
  kubectl get application -n argo-cd crossplane-aws-provider -w

  # Wait for providers to be healthy (this can take 2-3 minutes)
  kubectl get providers -w
  # Wait for: INSTALLED=True, HEALTHY=True

  # Verify ProviderConfig
  kubectl get providerconfig default
  ```

- [ ] **Task 1.5:** Create logging namespace

  ```bash
  kubectl create namespace logging
  ```

#### Testing
```bash
# Check providers installed
kubectl get providers
# Should see: provider-aws-s3 and provider-aws-iam with HEALTHY=True

# Check ProviderConfig
kubectl get providerconfig
kubectl describe providerconfig default

# Check Crossplane can authenticate to AWS
kubectl logs -n crossplane-system -l pkg.crossplane.io/provider=provider-aws-s3 --tail=50
# Should NOT see authentication errors

# Verify namespace
kubectl get namespace logging
```

#### Success Criteria
- ✅ Provider `provider-aws-s3` installed and healthy
- ✅ Provider `provider-aws-iam` installed and healthy
- ✅ ProviderConfig `default` created and configured
- ✅ No authentication errors in provider logs
- ✅ Namespace `logging` exists
- ✅ ArgoCD application synced successfully

---

### Phase 1.5: AWS Infrastructure via Crossplane (1 hour)

**Objective:** Deploy all AWS resources (S3 bucket, IAM user, policies) via Crossplane for complete GitOps automation

**Key Benefit:** After this phase, you'll never touch AWS CLI again. All changes through Git commits!

#### Tasks

- [ ] **Task 1.5.1:** Create S3 Bucket via Crossplane

  Create file: `base-apps/loki-aws-infrastructure/s3-bucket.yaml`
  ```yaml
  apiVersion: s3.aws.upbound.io/v1beta1
  kind: Bucket
  metadata:
    name: loki-logs-homelab
    labels:
      app: loki
  spec:
    forProvider:
      region: us-east-1
    providerConfigRef:
      name: default
  ```

- [ ] **Task 1.5.2:** Create S3 Lifecycle Configuration via Crossplane

  Create file: `base-apps/loki-aws-infrastructure/s3-lifecycle.yaml`
  ```yaml
  apiVersion: s3.aws.upbound.io/v1beta1
  kind: BucketLifecycleConfiguration
  metadata:
    name: loki-logs-lifecycle
  spec:
    forProvider:
      region: us-east-1
      bucketRef:
        name: loki-logs-homelab
      rule:
        - id: cost-optimization
          status: Enabled
          filter:
            - prefix: ""
          transition:
            - days: 30
              storageClass: STANDARD_IA
            - days: 90
              storageClass: DEEP_ARCHIVE
          expiration:
            - days: 365
    providerConfigRef:
      name: default
  ```

  **This automatically applies the lifecycle rules without needing AWS CLI!**

- [ ] **Task 1.5.3:** Create IAM Policy via Crossplane

  Create file: `base-apps/loki-aws-infrastructure/iam-policy.yaml`
  ```yaml
  apiVersion: iam.aws.upbound.io/v1beta1
  kind: Policy
  metadata:
    name: loki-s3-access
  spec:
    forProvider:
      policy: |
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Sid": "LokiS3Access",
              "Effect": "Allow",
              "Action": [
                "s3:ListBucket",
                "s3:PutObject",
                "s3:GetObject",
                "s3:DeleteObject"
              ],
              "Resource": [
                "arn:aws:s3:::loki-logs-homelab",
                "arn:aws:s3:::loki-logs-homelab/*"
              ]
            }
          ]
        }
    providerConfigRef:
      name: default
  ```

- [ ] **Task 1.5.4:** Create IAM User via Crossplane

  Create file: `base-apps/loki-aws-infrastructure/iam-user.yaml`
  ```yaml
  apiVersion: iam.aws.upbound.io/v1beta1
  kind: User
  metadata:
    name: loki-s3-user
  spec:
    forProvider:
      path: /serviceaccounts/
      tags:
        - key: Purpose
          value: Loki-S3-Access
        - key: ManagedBy
          value: Crossplane
    providerConfigRef:
      name: default
  ```

- [ ] **Task 1.5.5:** Attach Policy to User via Crossplane

  Create file: `base-apps/loki-aws-infrastructure/iam-policy-attachment.yaml`
  ```yaml
  apiVersion: iam.aws.upbound.io/v1beta1
  kind: UserPolicyAttachment
  metadata:
    name: loki-s3-user-policy
  spec:
    forProvider:
      policyArnSelector:
        matchLabels:
          crossplane.io/name: loki-s3-access
      userRef:
        name: loki-s3-user
    providerConfigRef:
      name: default
  ```

- [ ] **Task 1.5.6:** Create IAM Access Key via Crossplane

  Create file: `base-apps/loki-aws-infrastructure/iam-access-key.yaml`
  ```yaml
  apiVersion: iam.aws.upbound.io/v1beta1
  kind: AccessKey
  metadata:
    name: loki-s3-credentials
  spec:
    forProvider:
      userRef:
        name: loki-s3-user
    writeConnectionSecretToRef:
      name: loki-s3-credentials
      namespace: logging
    providerConfigRef:
      name: default
  ```

  **Important:** This creates a Kubernetes secret `loki-s3-credentials` in the `logging` namespace with:
  - `access_key_id`
  - `secret_access_key`

- [ ] **Task 1.5.7:** Sync credentials to Vault via ExternalSecret

  Create file: `base-apps/loki-aws-infrastructure/external-secret.yaml`
  ```yaml
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: loki-sync
    namespace: logging
  ---
  apiVersion: external-secrets.io/v1beta1
  kind: SecretStore
  metadata:
    name: vault-backend
    namespace: logging
  spec:
    provider:
      vault:
        server: "http://vault.vault.svc.cluster.local:8200"
        path: "k8s-secrets"
        version: "v2"
        auth:
          kubernetes:
            mountPath: "kubernetes"
            role: "logging"
            serviceAccountRef:
              name: "loki-sync"
  ---
  # This ExternalSecret PUSHES the Crossplane-generated credentials TO Vault
  apiVersion: external-secrets.io/v1beta1
  kind: PushSecret
  metadata:
    name: push-loki-credentials-to-vault
    namespace: logging
  spec:
    refreshInterval: 10s
    secretStoreRefs:
      - name: vault-backend
        kind: SecretStore
    selector:
      secret:
        name: loki-s3-credentials
    data:
      - match:
          secretKey: access_key_id
          remoteRef:
            remoteKey: logging/s3/access_key_id
      - match:
          secretKey: secret_access_key
          remoteRef:
            remoteKey: logging/s3/secret_access_key
  ```

  **Note:** We use `PushSecret` to push Crossplane-generated credentials INTO Vault for consistency.

- [ ] **Task 1.5.8:** Create ArgoCD Application for AWS Infrastructure

  Create file: `base-apps/loki-aws-infrastructure.yaml`
  ```yaml
  apiVersion: argoproj.io/v1alpha1
  kind: Application
  metadata:
    name: loki-aws-infrastructure
    namespace: argo-cd
  spec:
    project: default
    source:
      repoURL: https://github.com/arigsela/kubernetes
      targetRevision: main
      path: base-apps/loki-aws-infrastructure
    destination:
      server: https://kubernetes.default.svc
      namespace: logging
    syncPolicy:
      automated:
        prune: true
        selfHeal: true
      syncOptions:
        - CreateNamespace=false  # logging namespace created in Phase 1
    syncWaves:
      - order: 1  # Deploy before Loki
  ```

- [ ] **Task 1.5.9:** Deploy AWS infrastructure via GitOps

  ```bash
  # Commit and push
  git add base-apps/loki-aws-infrastructure*
  git commit -m "Add Loki AWS infrastructure via Crossplane (S3, IAM)"
  git push origin main

  # Wait for ArgoCD sync (watch progress)
  kubectl get application -n argo-cd loki-aws-infrastructure -w

  # Watch Crossplane create AWS resources
  kubectl get buckets,policies,users,accesskeys -n logging -w

  # This will take 2-3 minutes as Crossplane creates resources in AWS
  ```

#### Testing
```bash
# Verify S3 bucket created in AWS
kubectl get bucket loki-logs-homelab -o yaml | grep status -A 10
aws s3 ls | grep loki-logs-homelab

# Verify IAM user created
kubectl get user loki-s3-user -o yaml | grep status -A 5
aws iam get-user --user-name loki-s3-user

# Verify IAM policy created
kubectl get policy loki-s3-access -o yaml | grep arn
aws iam list-policies --scope Local | grep -i loki

# Verify access key secret created
kubectl get secret loki-s3-credentials -n logging
kubectl get secret loki-s3-credentials -n logging -o jsonpath='{.data.access_key_id}' | base64 -d

# Verify credentials pushed to Vault
vault kv get k8s-secrets/logging/s3

# Test S3 access with generated credentials
export AWS_ACCESS_KEY_ID=$(kubectl get secret loki-s3-credentials -n logging -o jsonpath='{.data.access_key_id}' | base64 -d)
export AWS_SECRET_ACCESS_KEY=$(kubectl get secret loki-s3-credentials -n logging -o jsonpath='{.data.secret_access_key}' | base64 -d)
aws s3 ls s3://loki-logs-homelab --region us-east-1
```

#### Success Criteria
- ✅ S3 bucket `loki-logs-homelab` created in AWS
- ✅ S3 lifecycle configuration applied (30d → STANDARD_IA, 90d → DEEP_ARCHIVE)
- ✅ IAM user `loki-s3-user` created
- ✅ IAM policy `loki-s3-access` created and attached to user
- ✅ Access key generated and stored in Kubernetes secret
- ✅ Credentials synced to Vault
- ✅ Test S3 access succeeds with generated credentials
- ✅ All resources have `crossplane.io/` labels for tracking

**🎉 Achievement Unlocked:** You now have ZERO manual AWS CLI steps. Everything is Git-managed!

---

### Phase 2: Loki Deployment (1 hour)

**Objective:** Deploy Loki in all-in-one mode with S3 backend

#### Tasks

- [x] **Task 2.1:** ~~Create ExternalSecret for S3 credentials~~ **COMPLETED IN PHASE 1.5**

  **Note:** This task is now completed by Crossplane in Phase 1.5! The credentials are:
  1. Auto-generated by Crossplane `AccessKey` resource
  2. Stored in K8s secret `loki-s3-credentials`
  3. Auto-synced to Vault by `PushSecret`

  The secret `loki-s3-credentials` already exists in the `logging` namespace with:
  - `access_key_id`
  - `secret_access_key`
  - `bucket_name` = `loki-logs-homelab`
  - `region` = `us-east-1`

  **No action needed - skip to Task 2.2!**

- [ ] **Task 2.2:** Create Loki ConfigMap

  Create file: `base-apps/logging/loki-config.yaml`
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: loki-config
    namespace: logging
  data:
    loki.yaml: |
      auth_enabled: false

      server:
        http_listen_port: 3100
        grpc_listen_port: 9096
        log_level: info

      common:
        path_prefix: /loki
        storage:
          s3:
            # S3 configuration - bucket created by Crossplane in Phase 1.5
            s3: s3://us-east-1
            bucketnames: loki-logs-homelab
            s3forcepathstyle: false
        replication_factor: 1
        ring:
          instance_addr: 127.0.0.1
          kvstore:
            store: inmemory

      schema_config:
        configs:
          - from: 2024-01-01
            store: tsdb
            object_store: s3
            schema: v13
            index:
              prefix: index_
              period: 24h

      storage_config:
        tsdb_shipper:
          active_index_directory: /loki/index
          cache_location: /loki/index_cache
          shared_store: s3
        aws:
          s3: s3://us-east-1/loki-logs-homelab
          s3forcepathstyle: false

      compactor:
        working_directory: /loki/compactor
        shared_store: s3
        compaction_interval: 10m
        retention_enabled: true
        retention_delete_delay: 2h
        retention_delete_worker_count: 150

      limits_config:
        retention_period: 720h  # 30 days
        enforce_metric_name: false
        reject_old_samples: true
        reject_old_samples_max_age: 168h
        ingestion_rate_mb: 10
        ingestion_burst_size_mb: 20
        max_cache_freshness_per_query: 10m

      chunk_store_config:
        max_look_back_period: 0s
        chunk_cache_config:
          enable_fifocache: true
          fifocache:
            max_size_mb: 500
            ttl: 1h

      table_manager:
        retention_deletes_enabled: true
        retention_period: 720h  # 30 days

      query_range:
        align_queries_with_step: true
        max_retries: 5
        cache_results: true
        results_cache:
          cache:
            enable_fifocache: true
            fifocache:
              max_size_mb: 500
              ttl: 1h

      frontend:
        encoding: protobuf
        max_outstanding_per_tenant: 2048
        compress_responses: true

      querier:
        max_concurrent: 4

      ingester:
        lifecycler:
          ring:
            kvstore:
              store: inmemory
            replication_factor: 1
        chunk_idle_period: 30m
        chunk_retain_period: 1m
        max_chunk_age: 1h
        chunk_encoding: snappy
        wal:
          enabled: true
          dir: /loki/wal
  ```

- [ ] **Task 2.3:** Create Loki Deployment

  Create file: `base-apps/logging/loki-deployment.yaml`
  ```yaml
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: loki
    namespace: logging
  ---
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: loki
    namespace: logging
    labels:
      app: loki
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: loki
    template:
      metadata:
        labels:
          app: loki
      spec:
        serviceAccountName: loki
        securityContext:
          fsGroup: 10001
          runAsUser: 10001
          runAsNonRoot: true
        containers:
        - name: loki
          image: grafana/loki:3.5.7
          args:
            - -config.file=/etc/loki/loki.yaml
            - -target=all
          ports:
          - containerPort: 3100
            name: http
            protocol: TCP
          - containerPort: 9096
            name: grpc
            protocol: TCP
          # Credentials automatically generated by Crossplane in Phase 1.5
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: loki-s3-credentials
                key: access_key_id
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: loki-s3-credentials
                key: secret_access_key
          - name: S3_BUCKET_NAME
            valueFrom:
              secretKeyRef:
                name: loki-s3-credentials
                key: bucket_name
          - name: AWS_REGION
            valueFrom:
              secretKeyRef:
                name: loki-s3-credentials
                key: region
          volumeMounts:
          - name: config
            mountPath: /etc/loki
          - name: storage
            mountPath: /loki
          resources:
            requests:
              cpu: 200m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi
          livenessProbe:
            httpGet:
              path: /ready
              port: 3100
            initialDelaySeconds: 45
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /ready
              port: 3100
            initialDelaySeconds: 45
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
        volumes:
        - name: config
          configMap:
            name: loki-config
        - name: storage
          emptyDir: {}
  ---
  apiVersion: v1
  kind: Service
  metadata:
    name: loki
    namespace: logging
    labels:
      app: loki
  spec:
    type: ClusterIP
    ports:
    - port: 3100
      targetPort: 3100
      protocol: TCP
      name: http
    - port: 9096
      targetPort: 9096
      protocol: TCP
      name: grpc
    selector:
      app: loki
  ```

- [ ] **Task 2.4:** Create ArgoCD Application for Loki

  Create file: `base-apps/loki.yaml`
  ```yaml
  apiVersion: argoproj.io/v1alpha1
  kind: Application
  metadata:
    name: loki
    namespace: argo-cd
  spec:
    project: default
    source:
      repoURL: https://github.com/arigsela/kubernetes
      targetRevision: main
      path: base-apps/logging
    destination:
      server: https://kubernetes.default.svc
      namespace: logging
    syncPolicy:
      automated:
        prune: true
        selfHeal: true
      syncOptions:
        - CreateNamespace=true
  ```

- [ ] **Task 2.5:** Deploy and verify Loki

  ```bash
  # Commit and push changes
  git add base-apps/logging/ base-apps/loki.yaml
  git commit -m "Deploy Loki with S3 backend"
  git push origin main

  # Wait for ArgoCD sync
  kubectl get application -n argo-cd loki -w

  # Verify deployment
  kubectl get pods -n logging -l app=loki
  kubectl logs -n logging -l app=loki --tail=50

  # Test Loki API
  kubectl port-forward -n logging svc/loki 3100:3100 &
  curl http://localhost:3100/ready
  curl http://localhost:3100/metrics
  ```

#### Testing
```bash
# Check Loki pod status
kubectl get pods -n logging

# View Loki logs
kubectl logs -n logging deployment/loki -f

# Verify S3 connection (check logs for S3 errors)
kubectl logs -n logging deployment/loki | grep -i s3

# Test Loki API endpoints
kubectl exec -n logging deployment/loki -- wget -qO- http://localhost:3100/ready
kubectl exec -n logging deployment/loki -- wget -qO- http://localhost:3100/metrics | grep loki_
```

#### Success Criteria
- ✅ Loki pod is Running
- ✅ Loki `/ready` endpoint returns HTTP 200
- ✅ No S3 authentication errors in logs
- ✅ S3 bucket shows objects being created
- ✅ ExternalSecret synced successfully

---

### Phase 2.5: Prometheus Deployment (45 minutes)

**Objective:** Deploy Prometheus for metrics collection and storage

#### Tasks

- [ ] **Task 2.5.1:** Create Prometheus ConfigMap

  Create file: `base-apps/logging/prometheus-config.yaml`
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus-config
    namespace: logging
  data:
    prometheus.yml: |
      global:
        scrape_interval: 15s
        scrape_timeout: 10s
        evaluation_interval: 15s
        external_labels:
          cluster: 'homelab'
          environment: 'production'

      # Alertmanager configuration (optional)
      alerting:
        alertmanagers:
          - static_configs:
              - targets: []

      # Load rules once and periodically evaluate them
      rule_files: []

      scrape_configs:
        # Prometheus self-monitoring
        - job_name: 'prometheus'
          static_configs:
            - targets: ['localhost:9090']

        # Kubernetes API server
        - job_name: 'kubernetes-apiservers'
          kubernetes_sd_configs:
            - role: endpoints
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
            - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
              action: keep
              regex: default;kubernetes;https

        # Kubernetes nodes
        - job_name: 'kubernetes-nodes'
          kubernetes_sd_configs:
            - role: node
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)

        # Kubernetes pods
        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
            - role: pod
          relabel_configs:
            # Only scrape pods with annotation prometheus.io/scrape: "true"
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true

            # Use custom scrape path if specified
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)

            # Use custom port if specified
            - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
              action: replace
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: $1:$2
              target_label: __address__

            # Add namespace label
            - source_labels: [__meta_kubernetes_namespace]
              action: replace
              target_label: namespace

            # Add pod label
            - source_labels: [__meta_kubernetes_pod_name]
              action: replace
              target_label: pod

            # Add container label
            - source_labels: [__meta_kubernetes_pod_container_name]
              action: replace
              target_label: container

            # Add app label
            - source_labels: [__meta_kubernetes_pod_label_app]
              action: replace
              target_label: app

        # Kubernetes services
        - job_name: 'kubernetes-services'
          kubernetes_sd_configs:
            - role: service
          metrics_path: /probe
          params:
            module: [http_2xx]
          relabel_configs:
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
              action: keep
              regex: true
            - source_labels: [__address__]
              target_label: __param_target
            - target_label: __address__
              replacement: blackbox-exporter:9115
            - source_labels: [__param_target]
              target_label: instance
            - action: labelmap
              regex: __meta_kubernetes_service_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              target_label: namespace
            - source_labels: [__meta_kubernetes_service_name]
              target_label: service
  ```

- [ ] **Task 2.5.2:** Create Prometheus StatefulSet

  Create file: `base-apps/logging/prometheus-statefulset.yaml`
  ```yaml
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus
    namespace: logging
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: prometheus
  rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: prometheus
  subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: logging
  ---
  apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: prometheus
    namespace: logging
    labels:
      app: prometheus
  spec:
    serviceName: prometheus
    replicas: 1
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "9090"
      spec:
        serviceAccountName: prometheus
        securityContext:
          fsGroup: 65534
          runAsUser: 65534
          runAsNonRoot: true
        containers:
        - name: prometheus
          image: prom/prometheus:v3.7.0
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--storage.tsdb.retention.time=15d'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
            - '--web.enable-lifecycle'
          ports:
          - containerPort: 9090
            name: http
            protocol: TCP
          volumeMounts:
          - name: config
            mountPath: /etc/prometheus
          - name: storage
            mountPath: /prometheus
          resources:
            requests:
              cpu: 200m
              memory: 512Mi
            limits:
              cpu: 500m
              memory: 1Gi
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
        volumes:
        - name: config
          configMap:
            name: prometheus-config
    volumeClaimTemplates:
    - metadata:
        name: storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: local-path  # K3s default storage class
        resources:
          requests:
            storage: 50Gi
  ---
  apiVersion: v1
  kind: Service
  metadata:
    name: prometheus
    namespace: logging
    labels:
      app: prometheus
  spec:
    type: ClusterIP
    ports:
    - port: 9090
      targetPort: 9090
      protocol: TCP
      name: http
    selector:
      app: prometheus
  ```

- [ ] **Task 2.5.3:** Deploy Prometheus

  ```bash
  # Commit and push changes
  git add base-apps/logging/prometheus-*
  git commit -m "Add Prometheus for metrics collection"
  git push origin main

  # Wait for ArgoCD sync

  # Verify deployment
  kubectl get statefulset -n logging prometheus
  kubectl get pods -n logging -l app=prometheus
  kubectl get pvc -n logging

  # Test Prometheus API
  kubectl port-forward -n logging svc/prometheus 9090:9090 &
  curl http://localhost:9090/-/healthy
  curl http://localhost:9090/api/v1/status/config
  ```

#### Testing
```bash
# Check Prometheus pod status
kubectl get pods -n logging -l app=prometheus

# View Prometheus logs
kubectl logs -n logging statefulset/prometheus -f

# Verify Prometheus is scraping targets
kubectl port-forward -n logging svc/prometheus 9090:9090 &
# Open http://localhost:9090/targets
# You should see kubernetes-pods, kubernetes-nodes, etc.

# Test a simple query
curl -G http://localhost:9090/api/v1/query \
  --data-urlencode 'query=up'
```

#### Success Criteria
- ✅ Prometheus pod is Running
- ✅ PVC created and bound (50GB)
- ✅ Prometheus UI accessible on port 9090
- ✅ Targets being discovered and scraped
- ✅ Metrics queryable via PromQL

---

### Phase 3: Enhanced Grafana Alloy Deployment (1 hour)

**Objective:** Deploy Grafana Alloy as DaemonSet to collect BOTH logs and metrics from all nodes

#### Tasks

- [ ] **Task 3.1:** Create Alloy RBAC permissions

  Create file: `base-apps/logging/alloy-rbac.yaml`
  ```yaml
  apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: alloy
    namespace: logging
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: alloy
  rules:
  - apiGroups: [""]
    resources:
    - nodes
    - nodes/proxy
    - services
    - endpoints
    - pods
    - events
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
    - configmaps
    verbs: ["get"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
  ---
  apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: alloy
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: alloy
  subjects:
  - kind: ServiceAccount
    name: alloy
    namespace: logging
  ```

- [ ] **Task 3.2:** Create Enhanced Alloy ConfigMap (Logs + Metrics)

  Create file: `base-apps/logging/alloy-config.yaml`
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: alloy-config
    namespace: logging
  data:
    config.alloy: |
      /********************************************/
      /*     LOGS COLLECTION (Loki)              */
      /********************************************/

      // Discover Kubernetes pods for logs
      discovery.kubernetes "pods" {
        role = "pod"
      }

      // Relabel to extract useful Kubernetes metadata
      discovery.relabel "pods" {
        targets = discovery.kubernetes.pods.targets

        // Keep only running pods
        rule {
          source_labels = ["__meta_kubernetes_pod_phase"]
          action        = "keep"
          regex         = "Running"
        }

        // Extract namespace
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          target_label  = "namespace"
        }

        // Extract pod name
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          target_label  = "pod"
        }

        // Extract container name
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          target_label  = "container"
        }

        // Extract app label
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app"]
          target_label  = "app"
        }

        // Set path to log files
        rule {
          source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
          target_label  = "__path__"
          separator     = "/"
          replacement   = "/var/log/pods/*$1/*.log"
        }
      }

      // Read container logs
      loki.source.kubernetes "pods" {
        targets    = discovery.relabel.pods.output
        forward_to = [loki.process.parse_logs.receiver]
      }

      // Process and parse logs
      loki.process "parse_logs" {
        // Extract JSON fields if logs are in JSON format
        stage.json {
          expressions = {
            level = "level",
            msg   = "msg",
          }
        }

        // Add timestamp
        stage.timestamp {
          source = "time"
          format = "RFC3339"
        }

        // Label extracted fields
        stage.labels {
          values = {
            level = "",
          }
        }

        forward_to = [loki.process.filter_logs.receiver]
      }

      // Filter out noisy logs
      loki.process "filter_logs" {
        // Drop health check logs
        stage.match {
          selector = "{app=\"nginx\"}"
          stage.drop {
            expression = ".*GET /health.*"
          }
        }

        // Drop verbose debug logs from production
        stage.match {
          selector = "{namespace!=\"development\"}"
          stage.drop {
            expression = ".*\\[DEBUG\\].*"
          }
        }

        forward_to = [loki.write.loki.receiver]
      }

      // Send logs to Loki
      loki.write "loki" {
        endpoint {
          url = "http://loki.logging.svc.cluster.local:3100/loki/api/v1/push"
          batch_wait = "1s"
          batch_size = 1048576 // 1MB
        }

        external_labels = {
          cluster = "homelab",
          source  = "alloy",
        }
      }

      /********************************************/
      /*   METRICS COLLECTION (Prometheus)       */
      /********************************************/

      // Discover Kubernetes pods for metrics
      discovery.kubernetes "metrics_pods" {
        role = "pod"
      }

      // Relabel for Prometheus metrics scraping
      discovery.relabel "metrics_pods" {
        targets = discovery.kubernetes.metrics_pods.targets

        // Keep only pods with prometheus.io/scrape annotation
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
          action        = "keep"
          regex         = "true"
        }

        // Use custom metrics path if specified
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
          action        = "replace"
          target_label  = "__metrics_path__"
          regex         = "(.+)"
          replacement   = "$1"
        }

        // Use custom port if specified
        rule {
          source_labels = ["__address__", "__meta_kubernetes_pod_annotation_prometheus_io_port"]
          action        = "replace"
          regex         = "([^:]+)(?::\\d+)?;(\\d+)"
          replacement   = "$1:$2"
          target_label  = "__address__"
        }

        // Add namespace label (SAME AS LOGS)
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          target_label  = "namespace"
        }

        // Add pod label (SAME AS LOGS)
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          target_label  = "pod"
        }

        // Add container label (SAME AS LOGS)
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          target_label  = "container"
        }

        // Add app label (SAME AS LOGS)
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app"]
          target_label  = "app"
        }

        // Add cluster label
        rule {
          target_label = "cluster"
          replacement  = "homelab"
        }
      }

      // Scrape metrics from discovered pods
      prometheus.scrape "pods" {
        targets    = discovery.relabel.metrics_pods.output
        forward_to = [prometheus.remote_write.prometheus.receiver]

        scrape_interval = "15s"
        scrape_timeout  = "10s"
      }

      // Discover Kubernetes nodes for metrics
      discovery.kubernetes "nodes" {
        role = "node"
      }

      // Relabel nodes
      discovery.relabel "nodes" {
        targets = discovery.kubernetes.nodes.output

        rule {
          source_labels = ["__meta_kubernetes_node_name"]
          target_label  = "node"
        }

        rule {
          source_labels = ["__address__"]
          target_label  = "__address__"
          regex         = "([^:]+)(?::\\d+)?"
          replacement   = "$1:10250"
        }

        rule {
          target_label = "cluster"
          replacement  = "homelab"
        }
      }

      // Scrape node metrics
      prometheus.scrape "nodes" {
        targets    = discovery.relabel.nodes.output
        forward_to = [prometheus.remote_write.prometheus.receiver]

        scrape_interval = "15s"
        scrape_timeout  = "10s"
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"

        tls_config {
          ca_file             = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
          insecure_skip_verify = false
        }
      }

      // Send metrics to Prometheus
      prometheus.remote_write "prometheus" {
        endpoint {
          url = "http://prometheus.logging.svc.cluster.local:9090/api/v1/write"

          queue_config {
            capacity          = 10000
            max_shards        = 10
            min_shards        = 1
            max_samples_per_send = 1000
            batch_send_deadline  = "5s"
            min_backoff          = "30ms"
            max_backoff          = "5s"
          }
        }

        external_labels = {
          cluster = "homelab",
          source  = "alloy",
        }
      }
  ```

  **Key Features:**
  - Collects BOTH logs and metrics in a single agent
  - Uses **same labels** for logs and metrics (namespace, pod, container, app)
  - Enables jumping between logs and metrics in Grafana
  - Discovers pods with `prometheus.io/scrape: "true"` annotation for metrics
  - Scrapes `/metrics` endpoints and node metrics

- [ ] **Task 3.3:** Create Alloy DaemonSet

  Create file: `base-apps/logging/alloy-daemonset.yaml`
  ```yaml
  apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    name: alloy
    namespace: logging
    labels:
      app: alloy
  spec:
    selector:
      matchLabels:
        app: alloy
    template:
      metadata:
        labels:
          app: alloy
      spec:
        serviceAccountName: alloy
        tolerations:
        - effect: NoSchedule
          operator: Exists
        containers:
        - name: alloy
          image: grafana/alloy:v1.11.0
          args:
            - run
            - /etc/alloy/config.alloy
            - --server.http.listen-addr=0.0.0.0:12345
            - --storage.path=/var/lib/alloy/data
          ports:
          - containerPort: 12345
            name: http
            protocol: TCP
          env:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          volumeMounts:
          - name: config
            mountPath: /etc/alloy
          - name: varlog
            mountPath: /var/log
            readOnly: true
          - name: varlibdockercontainers
            mountPath: /var/lib/docker/containers
            readOnly: true
          - name: data
            mountPath: /var/lib/alloy/data
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 300m
              memory: 256Mi
          securityContext:
            privileged: true
            runAsUser: 0
        volumes:
        - name: config
          configMap:
            name: alloy-config
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: data
          emptyDir: {}
  ```

- [ ] **Task 3.4:** Deploy and verify Alloy

  ```bash
  # Commit and push changes
  git add base-apps/logging/alloy-*
  git commit -m "Deploy Enhanced Grafana Alloy (logs + metrics collector)"
  git push origin main

  # Wait for ArgoCD sync

  # Verify DaemonSet
  kubectl get daemonset -n logging alloy
  kubectl get pods -n logging -l app=alloy

  # Check logs being collected
  kubectl logs -n logging -l app=alloy --tail=20

  # Check metrics being scraped
  kubectl logs -n logging -l app=alloy | grep "prometheus"
  ```

#### Testing
```bash
# Verify Alloy pods running on all nodes
kubectl get pods -n logging -l app=alloy -o wide

# Check Alloy is discovering pods for logs
kubectl logs -n logging -l app=alloy | grep -i "discovered"

# Check Alloy is sending to Loki
kubectl logs -n logging -l app=alloy | grep -i "loki"

# Check Alloy is scraping metrics
kubectl logs -n logging -l app=alloy | grep -i "prometheus"

# Port-forward to Alloy UI
kubectl port-forward -n logging daemonset/alloy 12345:12345 &
# Open http://localhost:12345 in browser
```

#### Success Criteria
- ✅ Alloy pod running on each K3s node
- ✅ Alloy discovering Kubernetes pods
- ✅ Alloy successfully sending logs to Loki
- ✅ Alloy successfully scraping and sending metrics to Prometheus
- ✅ No authentication errors in Alloy logs
- ✅ Same labels applied to both logs and metrics

---

### Phase 4: Complete Grafana Integration (30 minutes)

**Objective:** Configure Grafana with BOTH Loki (logs) and Prometheus (metrics) data sources

#### Tasks

- [ ] **Task 4.1:** Add both Loki and Prometheus data sources to Grafana

  Create file: `base-apps/grafana/datasources.yaml`
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: grafana-datasources
    namespace: monitoring  # or wherever your Grafana is deployed
    labels:
      grafana_datasource: "1"
  data:
    datasources.yaml: |
      apiVersion: 1
      datasources:
        # Loki for logs
        - name: Loki
          type: loki
          access: proxy
          url: http://loki.logging.svc.cluster.local:3100
          jsonData:
            maxLines: 1000
            derivedFields:
              # Link from logs to traces (if you add Tempo later)
              - datasourceUid: tempo
                matcherRegex: "traceID=(\\w+)"
                name: TraceID
                url: "$${__value.raw}"
          editable: true

        # Prometheus for metrics
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://prometheus.logging.svc.cluster.local:9090
          jsonData:
            timeInterval: "15s"
            queryTimeout: "60s"
            httpMethod: POST
          editable: true
          isDefault: true
  ```

  OR manually add via Grafana UI:
  ```
  Configuration → Data Sources → Add data source → Loki
  URL: http://loki.logging.svc.cluster.local:3100

  Configuration → Data Sources → Add data source → Prometheus
  URL: http://prometheus.logging.svc.cluster.local:9090
  ```

- [ ] **Task 4.2:** Create unified dashboard showing logs + metrics

  Create file: `base-apps/grafana/unified-observability-dashboard.json`
  ```json
  {
    "dashboard": {
      "title": "Complete Observability: Logs + Metrics",
      "uid": "observability-homelab",
      "tags": ["kubernetes", "observability", "homelab"],
      "timezone": "browser",
      "panels": [
        {
          "title": "Pod CPU Usage",
          "type": "graph",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "rate(container_cpu_usage_seconds_total{namespace=\"$namespace\", pod=~\"$pod\"}[5m])",
              "legendFormat": "{{pod}} - {{container}}",
              "refId": "A"
            }
          ],
          "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8}
        },
        {
          "title": "Pod Memory Usage",
          "type": "graph",
          "datasource": "Prometheus",
          "targets": [
            {
              "expr": "container_memory_working_set_bytes{namespace=\"$namespace\", pod=~\"$pod\"}",
              "legendFormat": "{{pod}} - {{container}}",
              "refId": "A"
            }
          ],
          "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8}
        },
        {
          "title": "Error Rate (from logs)",
          "type": "graph",
          "datasource": "Loki",
          "targets": [
            {
              "expr": "sum by (namespace) (rate({namespace=\"$namespace\"} |= \"error\" [5m]))",
              "legendFormat": "{{namespace}}",
              "refId": "A"
            }
          ],
          "gridPos": {"x": 0, "y": 8, "w": 12, "h": 8}
        },
        {
          "title": "Recent Error Logs",
          "type": "logs",
          "datasource": "Loki",
          "targets": [
            {
              "expr": "{namespace=\"$namespace\", pod=~\"$pod\"} |= \"error\"",
              "refId": "A"
            }
          ],
          "options": {
            "showTime": true,
            "showLabels": true,
            "wrapLogMessage": true
          },
          "gridPos": {"x": 12, "y": 8, "w": 12, "h": 8}
        },
        {
          "title": "All Logs (Live Tail)",
          "type": "logs",
          "datasource": "Loki",
          "targets": [
            {
              "expr": "{namespace=\"$namespace\", pod=~\"$pod\"}",
              "refId": "A"
            }
          ],
          "options": {
            "showTime": true,
            "showLabels": true,
            "wrapLogMessage": true
          },
          "gridPos": {"x": 0, "y": 16, "w": 24, "h": 10}
        }
      ],
      "templating": {
        "list": [
          {
            "name": "namespace",
            "type": "query",
            "datasource": "Prometheus",
            "query": "label_values(namespace)",
            "current": {
              "text": "chores-tracker",
              "value": "chores-tracker"
            }
          },
          {
            "name": "pod",
            "type": "query",
            "datasource": "Prometheus",
            "query": "label_values(kube_pod_info{namespace=\"$namespace\"}, pod)",
            "multi": true,
            "includeAll": true
          }
        ]
      }
    }
  }
  ```

- [ ] **Task 4.3:** Test queries in Grafana Explore

  **Prometheus (Metrics) queries:**
  ```promql
  # CPU usage by pod
  rate(container_cpu_usage_seconds_total{namespace="chores-tracker"}[5m])

  # Memory usage by pod
  container_memory_working_set_bytes{namespace="chores-tracker"}

  # Pod restart count
  kube_pod_container_status_restarts_total{namespace="chores-tracker"}

  # Request rate (if app exports metrics)
  rate(http_requests_total{namespace="chores-tracker"}[5m])
  ```

  **Loki (Logs) queries:**
  ```logql
  # All logs from namespace
  {namespace="chores-tracker"}

  # Error logs only
  {namespace="chores-tracker"} |= "error"

  # Rate of errors
  sum by (pod) (rate({namespace="chores-tracker"} |= "error" [1m]))

  # Logs from specific pod
  {namespace="chores-tracker", pod=~"chores-tracker-.*"}

  # Count errors by namespace
  sum by (namespace) (rate({job="alloy"} |= "error" [5m]))
  ```

- [ ] **Task 4.4:** Test label correlation (jumping between logs and metrics)

  **Scenario: High CPU Investigation**
  1. Start with Metrics (Prometheus):
     ```promql
     rate(container_cpu_usage_seconds_total{namespace="chores-tracker"}[5m])
     ```
     → See pod `chores-tracker-abc123` has 95% CPU

  2. Jump to Logs (Loki) using same labels:
     ```logql
     {namespace="chores-tracker", pod="chores-tracker-abc123"}
     ```
     → See logs: "Database query taking 30 seconds..."

  3. Root Cause Found!

#### Testing
```bash
# Access Grafana (if not already accessible)
kubectl port-forward -n monitoring svc/grafana 3000:80 &

# Open http://localhost:3000
# Login and navigate to Explore
# Test both data sources:
# 1. Select Prometheus data source → Run metric queries
# 2. Select Loki data source → Run log queries
# 3. Verify same labels appear in both
```

#### Success Criteria
- ✅ Loki data source shows "Connected" in Grafana
- ✅ Prometheus data source shows "Connected" in Grafana
- ✅ Can view logs in Grafana Explore (via Loki)
- ✅ Can query metrics in Grafana Explore (via Prometheus)
- ✅ Logs have proper labels (namespace, pod, container, app)
- ✅ Metrics have same labels as logs
- ✅ Can jump between metrics and logs using labels
- ✅ Unified dashboard displays both logs and metrics

---

### Phase 5: Testing & Validation (1 hour)

**Objective:** Comprehensive testing of the complete observability pipeline (logs + metrics)

#### Tasks

- [ ] **Task 5.1:** Generate test logs

  ```bash
  # Create test pod that generates logs
  kubectl run log-generator -n default --image=busybox \
    --restart=Never \
    --command -- sh -c \
    'while true; do echo "Test log entry at $(date)"; sleep 5; done'

  # Wait 1 minute for logs to accumulate
  sleep 60
  ```

- [ ] **Task 5.2:** Verify logs in Grafana (Loki)

  ```
  1. Open Grafana → Explore
  2. Select Loki data source
  3. Query: {namespace="default", pod="log-generator"}
  4. Verify logs appear
  5. Verify timestamps are correct
  6. Verify labels are populated
  ```

- [ ] **Task 5.3:** Generate test metrics (annotate a pod)

  ```bash
  # Create a test pod with Prometheus annotations
  cat <<EOF | kubectl apply -f -
  apiVersion: v1
  kind: Pod
  metadata:
    name: metrics-test
    namespace: default
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "8080"
  spec:
    containers:
    - name: metrics-exporter
      image: nginx
      ports:
      - containerPort: 8080
  EOF

  # Wait for metrics to be scraped
  sleep 60
  ```

- [ ] **Task 5.4:** Verify metrics in Grafana (Prometheus)

  ```
  1. Open Grafana → Explore
  2. Select Prometheus data source
  3. Query: up{namespace="default", pod="metrics-test"}
  4. Verify metrics appear
  5. Verify labels match log labels (namespace, pod, container)
  ```

- [ ] **Task 5.5:** Verify logs in S3

  ```bash
  # List objects in S3 bucket
  aws s3 ls s3://${BUCKET_NAME}/ --recursive

  # Should see:
  # - index/ directory (Loki index files)
  # - fake/ directory (Loki chunks)
  # - compactor/ directory (compacted data)

  # Check object count increasing
  aws s3 ls s3://${BUCKET_NAME}/fake/ --recursive | wc -l
  ```

- [ ] **Task 5.6:** Performance testing

  ```bash
  # Generate high-volume logs and metrics
  for i in {1..10}; do
    kubectl run log-gen-$i -n default --image=busybox \
      --restart=Never \
      --command -- sh -c \
      'while true; do echo "High volume test log $(date) $(head -c 1000 /dev/urandom | base64)"; sleep 0.1; done' &
  done

  # Monitor Loki performance
  kubectl top pod -n logging -l app=loki

  # Monitor Prometheus performance
  kubectl top pod -n logging -l app=prometheus

  # Monitor Alloy performance
  kubectl top pod -n logging -l app=alloy

  # Check query performance in Grafana
  # Query: {namespace="default"} |= "High volume test"
  # Measure query execution time

  # Cleanup
  kubectl delete pod -n default -l run=log-gen
  kubectl delete pod -n default log-generator metrics-test
  ```

#### Testing Checklist

| Test | Expected Result | Status |
|------|----------------|--------|
| Logs visible in Grafana | ✅ Logs appear within 10 seconds | ⬜ |
| Metrics visible in Grafana | ✅ Metrics queryable within 30 seconds | ⬜ |
| Labels populated on logs | ✅ namespace, pod, container labels present | ⬜ |
| Labels populated on metrics | ✅ Same labels as logs | ⬜ |
| Label correlation works | ✅ Can jump from metric to related logs | ⬜ |
| S3 objects created | ✅ Objects in S3 bucket increasing | ⬜ |
| Prometheus local storage | ✅ PVC usage increasing | ⬜ |
| Query performance | ✅ Recent logs/metrics query <2 seconds | ⬜ |
| Historical logs | ✅ 7-day old logs queryable | ⬜ |
| Log filtering | ✅ LogQL filters work correctly | ⬜ |
| Metric filtering | ✅ PromQL queries work correctly | ⬜ |
| Resource usage | ✅ Stack <3GB RAM total | ⬜ |

#### Success Criteria
- ✅ All test checklist items pass
- ✅ Logs from all namespaces visible in Grafana
- ✅ Metrics from all annotated pods in Grafana
- ✅ S3 bucket contains log chunks
- ✅ Prometheus PVC contains metrics data
- ✅ Query response time acceptable
- ✅ Label correlation enables jumping between logs and metrics
- ✅ No errors in Loki, Prometheus, or Alloy logs

---

### Phase 6: Production Optimization (30 minutes)

**Objective:** Fine-tune configuration for production use

#### Tasks

- [ ] **Task 6.1:** Configure log filtering

  Update `base-apps/logging/alloy-config.yaml` to filter noisy logs:
  ```alloy
  // Add more aggressive filtering
  loki.process "filter_logs" {
    // Drop health check logs from all apps
    stage.drop {
      expression = ".*GET /(health|healthz|readyz).*"
    }

    // Drop Kubernetes probe logs
    stage.drop {
      expression = ".*kube-probe.*"
    }

    // Drop DEBUG logs from production namespaces
    stage.match {
      selector = "{namespace!~\"dev.*|test.*\"}"
      stage.drop {
        expression = ".*\\[DEBUG\\].*"
      }
    }

    forward_to = [loki.write.loki.receiver]
  }
  ```

- [ ] **Task 6.2:** Set up alerting (optional)

  Create file: `base-apps/grafana/observability-alerts.yaml`
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: observability-alerts
    namespace: monitoring
  data:
    alerts.yaml: |
      groups:
        - name: observability_alerts
          interval: 1m
          rules:
            # Log-based alerts
            - alert: HighErrorRate
              expr: |
                sum(rate({job="alloy"} |= "error" [5m])) by (namespace) > 10
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "High error rate in {{ $labels.namespace }}"
                description: "Namespace {{ $labels.namespace }} has >10 errors/sec"

            # Metric-based alerts
            - alert: HighCPUUsage
              expr: |
                rate(container_cpu_usage_seconds_total{namespace!="kube-system"}[5m]) > 0.8
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "High CPU usage in {{ $labels.namespace }}"
                description: "Pod {{ $labels.pod }} CPU >80%"

            - alert: HighMemoryUsage
              expr: |
                container_memory_working_set_bytes{namespace!="kube-system"} /
                container_spec_memory_limit_bytes > 0.9
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "High memory usage in {{ $labels.namespace }}"
                description: "Pod {{ $labels.pod }} memory >90%"

            # Component health alerts
            - alert: LokiDown
              expr: |
                up{job="loki"} == 0
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Loki is down"
                description: "Loki has been down for 5 minutes"

            - alert: PrometheusDown
              expr: |
                up{job="prometheus"} == 0
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Prometheus is down"
                description: "Prometheus has been down for 5 minutes"
  ```

- [ ] **Task 6.3:** Enable monitoring metrics

  Add ServiceMonitor for Prometheus scraping (if you have Prometheus Operator):

  Create file: `base-apps/logging/servicemonitors.yaml`
  ```yaml
  apiVersion: monitoring.coreos.com/v1
  kind: ServiceMonitor
  metadata:
    name: loki
    namespace: logging
    labels:
      app: loki
  spec:
    selector:
      matchLabels:
        app: loki
    endpoints:
    - port: http
      path: /metrics
      interval: 30s
  ---
  apiVersion: monitoring.coreos.com/v1
  kind: ServiceMonitor
  metadata:
    name: prometheus
    namespace: logging
    labels:
      app: prometheus
  spec:
    selector:
      matchLabels:
        app: prometheus
    endpoints:
    - port: http
      path: /metrics
      interval: 30s
  ---
  apiVersion: monitoring.coreos.com/v1
  kind: ServiceMonitor
  metadata:
    name: alloy
    namespace: logging
    labels:
      app: alloy
  spec:
    selector:
      matchLabels:
        app: alloy
    endpoints:
    - port: http
      path: /metrics
      interval: 30s
  ```

- [ ] **Task 6.4:** Document operations procedures

  Create runbook: `docs/observability-operations-runbook.md` with:
  - Common LogQL queries
  - Common PromQL queries
  - Troubleshooting steps
  - Scaling guidelines
  - Backup/restore procedures
  - Cost monitoring
  - How to use logs + metrics together

#### Testing
```bash
# Verify filtered logs are not appearing
kubectl logs -n logging -l app=alloy | grep "dropped"

# Check Prometheus metrics (if configured)
kubectl port-forward -n logging svc/loki 3100:3100 &
curl http://localhost:3100/metrics | grep loki_ingester_streams_created_total

kubectl port-forward -n logging svc/prometheus 9090:9090 &
curl http://localhost:9090/metrics | grep prometheus_tsdb_

# Verify alerts are loaded (if configured)
# Check Grafana → Alerting
```

#### Success Criteria
- ✅ Noisy logs filtered out (health checks, debug logs)
- ✅ Metrics exposed and scrapable from all components
- ✅ Alerts configured for both logs and metrics (optional)
- ✅ Operations documentation created

---

## Configuration Details

### Loki Configuration Explained

| Setting | Value | Rationale |
|---------|-------|-----------|
| `retention_period` | 720h (30 days) | Balance between cost and availability |
| `chunk_encoding` | snappy | Fast compression with good ratio |
| `ingestion_rate_mb` | 10 MB/s | Sufficient for homelab, prevents overload |
| `max_look_back_period` | 0s | Unlimited query range |
| `compaction_interval` | 10m | Regular compaction reduces storage costs |

### Prometheus Configuration Explained

| Setting | Value | Rationale |
|---------|-------|-----------|
| `retention_time` | 15d | Sufficient for homelab, older metrics rarely needed |
| `scrape_interval` | 15s | Standard interval, balance between freshness and load |
| `storage.tsdb.path` | /prometheus | Local persistent storage via PVC |
| `remote_write` | Enabled | Alloy writes metrics via remote_write API |

### Grafana Alloy Configuration Explained

| Feature | Purpose |
|---------|---------|
| Kubernetes discovery | Automatically finds all pods and nodes |
| Label extraction | Adds namespace, pod, container metadata |
| JSON parsing | Extracts structured fields from JSON logs |
| Log filtering | Reduces noise and storage costs |
| Metrics scraping | Discovers and scrapes `/metrics` endpoints |
| Same labels | Uses identical labels for logs and metrics |
| Batching | Efficient network usage (1s batches, 1MB max) |
| Dual pipelines | Separate log and metric collection paths |

### S3 Storage Layout

```
s3://loki-logs-homelab-xxxxx/
├── index/              # TSDB index files
│   ├── index_19700/
│   └── ...
├── fake/               # Log chunks (named "fake" for historical reasons)
│   ├── <tenant>/
│   │   └── <chunks>/
└── compactor/          # Compacted data
    └── ...
```

### Prometheus Storage Layout

```
/prometheus/
├── chunks_head/        # Recent data (in memory)
├── wal/                # Write-ahead log
└── 01ABCD/             # Time-based blocks
    ├── chunks/         # Metric data
    ├── index           # Series index
    └── meta.json       # Block metadata
```

---

## How to Use Logs + Metrics Together

### Scenario 1: High CPU Investigation

1. **Start with Metrics (Prometheus):**
   ```promql
   rate(container_cpu_usage_seconds_total{namespace="chores-tracker"}[5m])
   ```
   → See pod `chores-tracker-abc123` has 95% CPU

2. **Jump to Logs (Loki):**
   ```logql
   {namespace="chores-tracker", pod="chores-tracker-abc123"}
   ```
   → See logs: "Database query taking 30 seconds..."

3. **Root Cause Found:** Slow database query causing high CPU!

### Scenario 2: Application Errors

1. **Start with Logs (Loki):**
   ```logql
   {namespace="chores-tracker"} |= "error"
   ```
   → See spike in errors at 14:23

2. **Check Metrics at That Time (Prometheus):**
   ```promql
   container_memory_working_set_bytes{namespace="chores-tracker"}
   ```
   → Memory was at 98% at 14:23

3. **Root Cause Found:** Out of memory causing errors!

### Scenario 3: Proactive Monitoring

1. **Dashboard shows:**
   - Prometheus: Request rate increasing
   - Prometheus: Response time increasing
   - Loki: No errors yet

2. **Scale up before errors occur:**
   ```bash
   kubectl scale deployment chores-tracker --replicas=3
   ```

3. **Prevented outage!**

---

## Annotating Your Applications for Metrics

To enable Prometheus scraping on your applications, add these annotations:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  template:
    metadata:
      annotations:
        prometheus.io/scrape: "true"  # Enable scraping
        prometheus.io/port: "8080"    # Metrics port
        prometheus.io/path: "/metrics" # Metrics endpoint (default)
    spec:
      containers:
      - name: my-app
        image: my-app:latest
        ports:
        - containerPort: 8080
          name: metrics
```

Your application must export metrics in Prometheus format at `/metrics`.

**Popular exporters:**
- **Go:** `prometheus/client_golang`
- **Python:** `prometheus/client_python`
- **Node.js:** `prom-client`
- **Java:** `micrometer`

---

## Testing & Validation

### Manual Testing Scenarios

#### Scenario 1: End-to-End Log Flow
1. Generate logs: `kubectl run test --image=busybox --command -- sh -c 'while true; do echo "Test"; sleep 1; done'`
2. Wait 30 seconds
3. Query in Grafana: `{pod="test"}`
4. Verify logs appear
5. Cleanup: `kubectl delete pod test`

#### Scenario 2: End-to-End Metrics Flow
1. Create pod with annotation: `prometheus.io/scrape: "true"`
2. Wait 30 seconds
3. Query in Grafana: `up{pod="test"}`
4. Verify metrics appear
5. Cleanup: `kubectl delete pod test`

#### Scenario 3: Log Filtering
1. Generate health check logs
2. Verify they don't appear in Loki (filtered by Alloy)
3. Generate error logs
4. Verify they DO appear in Loki

#### Scenario 4: S3 Storage
1. Wait 5 minutes after deployment
2. Check S3 bucket for objects
3. Verify objects are being created continuously
4. Check object sizes (should be compressed)

#### Scenario 5: Prometheus Storage
1. Check PVC size
2. Verify it's increasing over time
3. Check retention is working (15 days)

#### Scenario 6: Query Performance
1. Query last 1 hour of logs: `{namespace="chores-tracker"}`
2. Measure execution time (should be <2 seconds)
3. Query last 1 hour of metrics: `rate(container_cpu_usage_seconds_total[1h])`
4. Measure execution time (should be <2 seconds)

#### Scenario 7: Label Correlation
1. Find high CPU metric in Prometheus
2. Note the namespace and pod labels
3. Jump to Loki with same labels
4. Verify logs appear with same labels
5. Find root cause in logs

---

## Operations & Maintenance

### Daily Operations

#### Check System Health
```bash
# Check all pods
kubectl get pods -n logging

# Check Loki health
kubectl exec -n logging deployment/loki -- wget -qO- http://localhost:3100/ready

# Check Prometheus health
kubectl exec -n logging statefulset/prometheus -- wget -qO- http://localhost:9090/-/healthy

# Check Alloy collection (logs + metrics)
kubectl logs -n logging -l app=alloy --tail=20

# Check recent S3 uploads
aws s3 ls s3://${BUCKET_NAME}/fake/ --recursive | tail -20

# Check Prometheus storage usage
kubectl exec -n logging statefulset/prometheus -- df -h /prometheus
```

#### Monitor Costs
```bash
# Check S3 storage usage
aws s3 ls s3://${BUCKET_NAME} --recursive --summarize | tail -2

# Calculate monthly cost
# Storage size (GB) × $0.023 = monthly cost
```

### Weekly Operations

#### Review Log Volume
```grafana
# In Grafana Explore (Loki)
sum(rate({job="alloy"}[1w])) by (namespace)
```

#### Review Metrics Cardinality
```promql
# In Grafana Explore (Prometheus)
count(up) by (namespace)
```

#### Check for Errors
```bash
# Check Loki errors
kubectl logs -n logging deployment/loki | grep -i error

# Check Prometheus errors
kubectl logs -n logging statefulset/prometheus | grep -i error

# Check Alloy errors
kubectl logs -n logging -l app=alloy | grep -i error
```

### Monthly Operations

#### Review Retention Policy
- Verify old logs are being deleted from S3
- Verify old metrics are being deleted from Prometheus
- Check S3 lifecycle rules are working
- Review storage costs

#### Update Components
```bash
# Check for new versions
# Loki: https://github.com/grafana/loki/releases
# Prometheus: https://github.com/prometheus/prometheus/releases
# Alloy: https://github.com/grafana/alloy/releases

# Update image versions in manifests
# Commit and push - ArgoCD will auto-deploy
```

### Common Queries

#### LogQL Queries (Loki)

```
# All logs from a namespace
{namespace="chores-tracker"}

# Error logs only
{namespace="chores-tracker"} |= "error"

# JSON field filtering
{namespace="chores-tracker"} | json | level="ERROR"

# Rate of errors
sum by (namespace) (rate({job="alloy"} |= "error" [5m]))

# Logs from specific time range
{namespace="chores-tracker"}[24h]

# Pattern matching
{namespace="chores-tracker"} |~ "status: (500|503)"

# Count log lines
count_over_time({namespace="chores-tracker"}[1h])

# Top 10 pods by log volume
topk(10, sum by (pod) (rate({namespace="chores-tracker"}[5m])))
```

#### PromQL Queries (Prometheus)

```
# CPU usage by pod
rate(container_cpu_usage_seconds_total{namespace="chores-tracker"}[5m])

# Memory usage by pod
container_memory_working_set_bytes{namespace="chores-tracker"}

# Pod restart count
kube_pod_container_status_restarts_total{namespace="chores-tracker"}

# Request rate (if app exports metrics)
rate(http_requests_total{namespace="chores-tracker"}[5m])

# Error rate (if app exports metrics)
rate(http_requests_total{namespace="chores-tracker", status=~"5.."}[5m])

# P95 latency (if app exports metrics)
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Top 10 pods by CPU
topk(10, rate(container_cpu_usage_seconds_total[5m]))
```

### Scaling Guidelines

#### When to Scale Up

**Indicators:**
- Loki pod memory >80%
- Prometheus pod memory >80%
- Query latency >5 seconds
- S3 storage >100GB
- Prometheus storage >40GB (of 50GB PVC)

**Scaling Options:**

1. **Vertical scaling:** Increase memory/CPU
   ```yaml
   resources:
     limits:
       memory: 2Gi  # Increase from 1Gi
   ```

2. **Horizontal scaling for Loki:** Split into microservices mode
   ```yaml
   # Split into separate components:
   - loki-distributor (2 replicas)
   - loki-ingester (3 replicas)
   - loki-querier (2 replicas)
   - loki-query-frontend (2 replicas)
   - loki-compactor (1 replica)
   ```

3. **Increase Prometheus storage:** Resize PVC
   ```bash
   kubectl patch pvc storage-prometheus-0 -n logging \
     -p '{"spec":{"resources":{"requests":{"storage":"100Gi"}}}}'
   ```

4. **Storage optimization:** Increase compression, reduce retention
   ```yaml
   # Loki: reduce retention
   limits_config:
     retention_period: 360h  # 15 days instead of 30

   # Prometheus: reduce retention
   args:
     - '--storage.tsdb.retention.time=7d'  # 7 days instead of 15
   ```

---

## Troubleshooting

### Issue: Loki Pod Not Starting

**Symptoms:**
- Pod in CrashLoopBackOff
- Error: "cannot connect to S3"

**Diagnosis:**
```bash
kubectl logs -n logging deployment/loki
```

**Solutions:**
1. Check S3 credentials in secret
   ```bash
   kubectl get secret -n logging loki-s3-credentials -o yaml
   ```

2. Verify ExternalSecret synced
   ```bash
   kubectl get externalsecret -n logging loki-s3-credentials
   ```

3. Test S3 access manually
   ```bash
   kubectl run aws-cli --rm -it --image=amazon/aws-cli -- \
     s3 ls s3://${BUCKET_NAME} --region ${AWS_REGION}
   ```

4. Check Vault connectivity
   ```bash
   kubectl get secretstore -n logging vault-backend
   kubectl describe secretstore -n logging vault-backend
   ```

---

### Issue: Prometheus Pod Not Starting

**Symptoms:**
- Pod in CrashLoopBackOff
- Error: "failed to create TSDB"

**Diagnosis:**
```bash
kubectl logs -n logging statefulset/prometheus
```

**Solutions:**
1. Check PVC is bound
   ```bash
   kubectl get pvc -n logging
   ```

2. Check PVC has enough space
   ```bash
   kubectl exec -n logging statefulset/prometheus -- df -h /prometheus
   ```

3. Verify local-path storage class exists
   ```bash
   kubectl get storageclass
   ```

4. Check for permission issues
   ```bash
   kubectl logs -n logging statefulset/prometheus | grep -i permission
   ```

---

### Issue: No Logs Appearing in Grafana

**Symptoms:**
- Grafana shows "No logs found"
- Loki is running

**Diagnosis:**
```bash
# Check Alloy is running
kubectl get pods -n logging -l app=alloy

# Check Alloy is discovering pods
kubectl logs -n logging -l app=alloy | grep discovered

# Check Alloy is sending to Loki
kubectl logs -n logging -l app=alloy | grep loki
```

**Solutions:**
1. Verify Alloy can reach Loki
   ```bash
   kubectl exec -n logging daemonset/alloy -- \
     wget -qO- http://loki.logging.svc.cluster.local:3100/ready
   ```

2. Check Loki received logs
   ```bash
   # Query Loki API directly
   kubectl port-forward -n logging svc/loki 3100:3100 &
   curl 'http://localhost:3100/loki/api/v1/query?query={job="alloy"}'
   ```

3. Verify pod discovery
   ```bash
   # Check Alloy discovered your pods
   kubectl port-forward -n logging daemonset/alloy 12345:12345 &
   # Open http://localhost:12345 → Check targets
   ```

4. Check Alloy RBAC permissions
   ```bash
   kubectl auth can-i list pods --as=system:serviceaccount:logging:alloy -n default
   ```

---

### Issue: No Metrics Appearing in Grafana

**Symptoms:**
- Grafana shows "No data"
- Prometheus is running

**Diagnosis:**
```bash
# Check Alloy is scraping metrics
kubectl logs -n logging -l app=alloy | grep prometheus

# Check Prometheus is receiving metrics
kubectl logs -n logging statefulset/prometheus | grep "remote write"
```

**Solutions:**
1. Verify pods have Prometheus annotations
   ```bash
   kubectl get pods -A -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.annotations.prometheus\.io/scrape}{"\n"}{end}'
   ```

2. Add annotations to your deployments
   ```yaml
   annotations:
     prometheus.io/scrape: "true"
     prometheus.io/port: "8080"
     prometheus.io/path: "/metrics"
   ```

3. Check Alloy can reach pod metrics endpoints
   ```bash
   kubectl port-forward -n <namespace> pod/<pod-name> 8080:8080 &
   curl http://localhost:8080/metrics
   ```

4. Verify Prometheus is accepting remote_write
   ```bash
   kubectl port-forward -n logging svc/prometheus 9090:9090 &
   curl -X POST http://localhost:9090/api/v1/write
   ```

---

### Issue: High S3 Costs

**Symptoms:**
- S3 bill higher than expected
- Storage growing rapidly

**Diagnosis:**
```bash
# Check S3 bucket size
aws s3 ls s3://${BUCKET_NAME} --recursive --summarize

# Check number of objects
aws s3 ls s3://${BUCKET_NAME} --recursive | wc -l

# Identify largest directories
aws s3 ls s3://${BUCKET_NAME}/ --recursive | \
  awk '{print $4}' | cut -d'/' -f1-2 | sort | uniq -c | sort -rn
```

**Solutions:**
1. Enable/verify S3 lifecycle rules
   ```bash
   aws s3api get-bucket-lifecycle-configuration --bucket ${BUCKET_NAME}
   ```

2. Reduce Loki retention period
   ```yaml
   # In loki-config.yaml
   limits_config:
     retention_period: 360h  # Reduce from 720h to 15 days
   ```

3. Increase log filtering in Alloy
   ```alloy
   // Filter more aggressively
   stage.drop {
     expression = ".*verbose.*|.*trace.*|.*debug.*"
   }
   ```

4. Enable compaction
   ```yaml
   # Verify in loki-config.yaml
   compactor:
     compaction_interval: 10m
     retention_enabled: true
   ```

---

### Issue: Prometheus Storage Full

**Symptoms:**
- Error: "no space left on device"
- Metrics not being saved

**Diagnosis:**
```bash
# Check PVC usage
kubectl exec -n logging statefulset/prometheus -- df -h /prometheus

# Check retention settings
kubectl logs -n logging statefulset/prometheus | grep retention
```

**Solutions:**
1. Reduce retention period
   ```yaml
   args:
     - '--storage.tsdb.retention.time=7d'  # Reduce from 15d to 7d
   ```

2. Resize PVC (if storage class supports it)
   ```bash
   kubectl patch pvc storage-prometheus-0 -n logging \
     -p '{"spec":{"resources":{"requests":{"storage":"100Gi"}}}}'
   ```

3. Clean up old data manually
   ```bash
   kubectl exec -n logging statefulset/prometheus -- \
     rm -rf /prometheus/01ABC*  # Remove old blocks
   ```

---

### Issue: Slow Query Performance

**Symptoms:**
- Queries take >10 seconds
- Grafana times out

**Diagnosis:**
```bash
# Check Loki resource usage
kubectl top pod -n logging -l app=loki

# Check Prometheus resource usage
kubectl top pod -n logging -l app=prometheus

# Check query execution time in logs
kubectl logs -n logging deployment/loki | grep "query_time"
kubectl logs -n logging statefulset/prometheus | grep "query"
```

**Solutions:**
1. Increase memory for Loki and Prometheus
   ```yaml
   resources:
     limits:
       memory: 2Gi  # Increase from 1Gi
   ```

2. Limit query time range
   ```yaml
   # Loki
   limits_config:
     max_query_length: 720h  # Don't query beyond 30 days

   # Use smaller time ranges in queries
   {namespace="chores-tracker"}[1h]  # Instead of [7d]
   ```

3. Optimize queries
   ```
   # Instead of:
   {namespace="chores-tracker"}[30d]

   # Use:
   {namespace="chores-tracker"}[1h]  # Smaller time range
   ```

4. Add more cache
   ```yaml
   # Loki
   chunk_store_config:
     chunk_cache_config:
       fifocache:
         max_size_mb: 1000  # Increase cache
   ```

---

### Issue: Alloy High Memory Usage

**Symptoms:**
- Alloy pods using >500MB RAM
- Pods being OOMKilled

**Diagnosis:**
```bash
# Check memory usage
kubectl top pod -n logging -l app=alloy

# Check number of targets
kubectl logs -n logging -l app=alloy | grep "targets discovered"
```

**Solutions:**
1. Reduce batch size for logs
   ```alloy
   loki.write "loki" {
     endpoint {
       batch_size = 524288  # Reduce from 1MB to 512KB
     }
   }
   ```

2. Reduce queue size for metrics
   ```alloy
   prometheus.remote_write "prometheus" {
     endpoint {
       queue_config {
         capacity = 5000  # Reduce from 10000
       }
     }
   }
   ```

3. Increase memory limit
   ```yaml
   resources:
     limits:
       memory: 512Mi  # Increase from 256Mi
   ```

4. Filter logs earlier in pipeline
   ```alloy
   // Drop logs before processing
   loki.source.kubernetes "pods" {
     targets = discovery.relabel.pods.output
     forward_to = [loki.process.filter_first.receiver]
   }

   loki.process "filter_first" {
     stage.drop {
       expression = ".*health.*"
     }
     forward_to = [loki.process.parse_logs.receiver]
   }
   ```

---

### Issue: Labels Not Matching Between Logs and Metrics

**Symptoms:**
- Can't jump from metrics to logs
- Different labels on logs vs metrics

**Diagnosis:**
```bash
# Check labels in Loki
kubectl port-forward -n logging svc/loki 3100:3100 &
curl 'http://localhost:3100/loki/api/v1/labels'

# Check labels in Prometheus
kubectl port-forward -n logging svc/prometheus 9090:9090 &
curl 'http://localhost:9090/api/v1/labels'
```

**Solutions:**
1. Verify Alloy config has same label rules for both logs and metrics
   - Check that `namespace`, `pod`, `container`, `app` labels are extracted the same way

2. Update Alloy config to ensure consistent labeling:
   ```alloy
   // Logs section
   rule {
     source_labels = ["__meta_kubernetes_namespace"]
     target_label  = "namespace"
   }

   // Metrics section (MUST be identical)
   rule {
     source_labels = ["__meta_kubernetes_namespace"]
     target_label  = "namespace"
   }
   ```

---

## Rollback Plan

### Quick Rollback (if deployment fails)

```bash
# Option 1: ArgoCD rollback to previous version
kubectl patch application loki -n argo-cd --type merge \
  -p '{"spec":{"syncPolicy":{"automated":null}}}'

argocd app rollback loki --revision 1

# Option 2: Manual deletion
kubectl delete -f base-apps/loki.yaml
kubectl delete namespace logging

# Option 3: Git revert
git revert HEAD
git push origin main
# ArgoCD will auto-sync the rollback
```

### Gradual Rollback (if issues found in production)

1. Disable auto-sync
   ```bash
   kubectl patch application loki -n argo-cd --type merge \
     -p '{"spec":{"syncPolicy":{"automated":null}}}'
   ```

2. Stop log and metric collection
   ```bash
   kubectl scale daemonset -n logging alloy --replicas=0
   ```

3. Investigate issues
   ```bash
   kubectl logs -n logging deployment/loki
   kubectl logs -n logging statefulset/prometheus
   kubectl describe pod -n logging -l app=loki
   kubectl describe pod -n logging -l app=prometheus
   ```

4. If unfixable, delete deployment
   ```bash
   kubectl delete application -n argo-cd loki
   kubectl delete namespace logging
   ```

5. Clean up S3 (optional)
   ```bash
   aws s3 rm s3://${BUCKET_NAME} --recursive
   aws s3 rb s3://${BUCKET_NAME}
   ```

---

## Next Steps After Implementation

### Immediate (Day 1)
- [ ] Create common LogQL and PromQL queries dashboard
- [ ] Set up alerts for error rates and resource usage
- [ ] Document access URLs and credentials
- [ ] Share with team

### Short-term (Week 1)
- [ ] Monitor S3 costs daily
- [ ] Tune log filtering based on volume
- [ ] Create application-specific dashboards
- [ ] Optimize retention based on usage
- [ ] Annotate existing applications with Prometheus scrape annotations

### Long-term (Month 1)
- [ ] Evaluate moving Loki to microservices mode if needed
- [ ] Consider adding Tempo for traces (complete observability: logs + metrics + traces)
- [ ] Implement log-based metrics
- [ ] Review and optimize costs
- [ ] Create runbooks for common issues

---

## Summary of Implementation

### What You've Built

| Component | What It Does | Where Data Goes |
|-----------|--------------|-----------------|
| **Grafana Alloy** | Collects logs AND metrics from all pods | Sends logs to Loki, metrics to Prometheus |
| **Loki** | Stores and indexes logs | AWS S3 (30-day retention) |
| **Prometheus** | Stores and queries metrics | Local PVC (15-day retention) |
| **Grafana** | Visualizes logs and metrics | Queries Loki and Prometheus |

### Key Benefits Achieved

✅ **Complete Observability**: Logs + Metrics in one place
✅ **Cost Efficient**: $0.50-3/month vs $1,200-4,500/month for Datadog
✅ **Label Correlation**: Jump from high CPU metric → related error logs
✅ **GitOps**: Everything deployed via ArgoCD
✅ **Scalable**: S3 for logs (unlimited), local for metrics (sufficient)
✅ **Modern**: Latest Grafana stack (2025)

### Total Cost

| Component | Cost |
|-----------|------|
| Logs (S3) | $0.50-3/month |
| Metrics (Local PVC) | $0/month |
| **Total** | **$0.50-3/month** |

**99.9% cheaper than Datadog!**

---

## References

### Documentation
- [Grafana Loki Documentation](https://grafana.com/docs/loki/latest/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Alloy Documentation](https://grafana.com/docs/alloy/latest/)
- [LogQL Language](https://grafana.com/docs/loki/latest/query/)
- [PromQL Language](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [AWS S3 Pricing](https://aws.amazon.com/s3/pricing/)

### Useful Commands Cheatsheet

```bash
# Loki health check
kubectl exec -n logging deployment/loki -- wget -qO- http://localhost:3100/ready

# Prometheus health check
kubectl exec -n logging statefulset/prometheus -- wget -qO- http://localhost:9090/-/healthy

# View Loki metrics
kubectl port-forward -n logging svc/loki 3100:3100 &
curl http://localhost:3100/metrics

# View Prometheus metrics
kubectl port-forward -n logging svc/prometheus 9090:9090 &
curl http://localhost:9090/metrics

# Query Loki API directly
curl -G -s "http://localhost:3100/loki/api/v1/query" \
  --data-urlencode 'query={namespace="default"}' | jq

# Query Prometheus API directly
curl -G -s "http://localhost:9090/api/v1/query" \
  --data-urlencode 'query=up' | jq

# Check S3 bucket size
aws s3 ls s3://${BUCKET_NAME} --recursive --summarize | tail -2

# Check Prometheus storage usage
kubectl exec -n logging statefulset/prometheus -- df -h /prometheus

# Test S3 connectivity from pod
kubectl run aws-test --rm -it --image=amazon/aws-cli -- \
  s3 ls s3://${BUCKET_NAME}

# View Alloy targets (logs + metrics)
kubectl port-forward -n logging daemonset/alloy 12345:12345 &
# Open http://localhost:12345

# Stream logs from Alloy
kubectl logs -n logging -l app=alloy -f

# Force ArgoCD sync
argocd app sync loki

# Check ArgoCD application status
argocd app get loki
```

---

## Appendix

### A. Cost Calculator

Use this formula to estimate monthly S3 costs:

```
Raw Logs Per Day (GB) = Number of Pods × Average Log Size Per Pod Per Day
Compressed Logs Per Day (GB) = Raw Logs ÷ Compression Ratio (10x typical)
Monthly Storage (GB) = Compressed Logs Per Day × Retention Days
Monthly Cost = Monthly Storage × $0.023

Example:
20 pods × 0.25 GB/pod/day = 5 GB/day raw
5 GB ÷ 10 = 0.5 GB/day compressed
0.5 GB × 30 days = 15 GB stored
15 GB × $0.023 = $0.35/month
```

**Prometheus is FREE** (uses local PVC storage)

### B. Resource Requirements

| Component | CPU Request | CPU Limit | Memory Request | Memory Limit |
|-----------|-------------|-----------|----------------|--------------|
| Loki | 200m | 500m | 512Mi | 1Gi |
| Prometheus | 200m | 500m | 512Mi | 1Gi |
| Alloy (per node) | 100m | 300m | 128Mi | 256Mi |
| Grafana | 100m | 200m | 256Mi | 512Mi |

**Total for 3-node cluster:**
- CPU: 1.2 cores request, 2.5 cores limit
- Memory: 2.2GB request, 4.3GB limit

### C. Glossary

| Term | Definition |
|------|------------|
| **Alloy** | Modern unified telemetry collection agent from Grafana (replaces Promtail) |
| **Chunk** | Compressed block of log data stored in S3 |
| **Distributor** | Loki component that receives logs from agents |
| **Ingester** | Loki component that writes chunks to storage |
| **LogQL** | Query language for Loki (similar to PromQL) |
| **PromQL** | Query language for Prometheus metrics |
| **TSDB** | Time Series Database used for Loki index and Prometheus storage |
| **WAL** | Write-Ahead Log for crash recovery |
| **Remote Write** | Prometheus API for pushing metrics |
| **Label Correlation** | Using same labels on logs and metrics to enable jumping between them |

---

**End of Complete Observability Implementation Plan**

---

## Change Log

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-10-16 | Claude | Initial logs-only implementation plan created |
| 2.0 | 2025-10-16 | Claude | Added Prometheus metrics, enhanced Alloy config, merged documents |
| 3.0 | 2025-10-17 | Claude | **Major Update:** Converted to 100% GitOps with Crossplane AWS provider. Eliminated all manual AWS CLI commands. Added Phase 1 (Crossplane setup) and Phase 1.5 (AWS infrastructure via Crossplane). All S3 buckets, IAM users, policies, and credentials now managed declaratively through Git. Added Terraform IAM resources (`terraform/roots/asela-cluster/iam.tf`) for Crossplane admin user provisioning. |
| 3.0.1 | 2025-10-17 | Claude | **Bug Fix:** Removed `namespace` field from Provider resources. Provider (pkg.crossplane.io/v1) is a cluster-scoped resource and must not have a namespace specified. This was causing ArgoCD sync timeouts. |
